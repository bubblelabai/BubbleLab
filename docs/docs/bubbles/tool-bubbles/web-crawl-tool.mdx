# Web Crawl Tool

Multi-page web crawling tool for exploring entire websites and subdomains.

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Quick Start

```typescript
import { WebCrawlTool } from '@bubblelab/bubble-core';
import { CredentialType } from '@bubblelab/shared-schemas';
const result = await new WebCrawlTool({

  url: 'example', // The root URL to crawl and extract content from
  credentials: {
    [CredentialType.FIRECRAWL_API_KEY]: process.env.FIRECRAWL_API_KEY as string,
  },
}).action();
```

## Operation Details

### `execute`

<Tabs values={[
  { label: 'Input Schema', value: 'input' },
  { label: 'Output Schema', value: 'output' }
]} defaultValue="input">
  <TabItem value="input">

<div className="schema-card">
<dl>
  <dt><code>url</code> <em>string</em> <span style={{color:'#d32f2f',fontWeight:600}}>required</span></dt>
  <dd>The root URL to crawl and extract content from</dd>

  <dt><code>format</code> <em>'markdown'</em> </dt>
  <dd>Output format for crawled content</dd>

  <dt><code>onlyMainContent</code> <em>boolean</em> </dt>
  <dd>Extract only main content, filtering out navigation/footers</dd>

  <dt><code>maxPages</code> <em>number</em> </dt>
  <dd>Maximum number of pages to crawl</dd>

  <dt><code>crawlDepth</code> <em>number</em> </dt>
  <dd>Maximum depth to crawl</dd>

  <dt><code>includePaths</code> <em>string[]</em> </dt>
  <dd>URL patterns to include in crawl (regex patterns), Example: ["^/blog/.*$", "^/docs/.*$"]</dd>

  <dt><code>excludePaths</code> <em>string[]</em> </dt>
  <dd>URL patterns to exclude from crawl (regex patterns), ["^/admin/.*$", "^/private/.*$"]</dd>

  <dt><code>waitFor</code> <em>number</em> </dt>
  <dd>Time to wait for dynamic content in milliseconds</dd>

  <dt><code>credentials</code> <em>Record&lt;CredentialType,string&gt;</em> </dt>
  <dd>Required credentials including FIRECRAWL_API_KEY</dd>
</dl>

</div>

  </TabItem>
  <TabItem value="output">

<div className="schema-card">
<dl>
  <dt><code>url</code> <em>string</em> <span style={{color:'#d32f2f',fontWeight:600}}>required</span></dt>
  <dd>The original URL that was crawled</dd>

  <dt><code>success</code> <em>boolean</em> <span style={{color:'#d32f2f',fontWeight:600}}>required</span></dt>
  <dd>Whether the crawl operation was successful</dd>

  <dt><code>error</code> <em>string</em> <span style={{color:'#d32f2f',fontWeight:600}}>required</span></dt>
  <dd>Error message if crawl failed</dd>

  <dt><code>pages</code> <em>object[]</em> <span style={{color:'#d32f2f',fontWeight:600}}>required</span></dt>
  <dd>Array of crawled pages with content</dd>

  <dt><code>totalPages</code> <em>number</em> <span style={{color:'#d32f2f',fontWeight:600}}>required</span></dt>
  <dd>Total number of pages crawled</dd>

  <dt><code>creditsUsed</code> <em>number</em> <span style={{color:'#d32f2f',fontWeight:600}}>required</span></dt>
  <dd>Number of credits used</dd>

  <dt><code>metadata</code> <em>object</em> </dt>
  <dd>Additional metadata about the crawl operation</dd>
</dl>

</div>

  </TabItem>
</Tabs>

